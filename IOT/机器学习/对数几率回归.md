对数几率回归使用`Sigmoid`函数将连续值转换为概率值。
![](https://cdn.nlark.com/yuque/__latex/fd04a8e34b064c2829f616c2d98073db.svg#card=math&code=y%20%3D%20%5Cfrac%7B1%7D%7B1%2Be%5E%7B-z%7D%7D&id=J8JZi)
![](https://cdn.jsdelivr.net/gh/xuezhaorong/Picgo//Source/fix-dir/Download/1/2024/06/01/16-36-57-f6dce770d2bc2e10db2346ecc80d932e-%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20240601163500-92aa4e.png#id=nT9j1&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none)
将`Linear Regression`的函数表达式代入后得到：
![](https://cdn.nlark.com/yuque/__latex/476d5b52468caf8291013ced3c4e464c.svg#card=math&code=y%20%3D%20%5Cfrac%7B1%7D%7B1%2Be%5E%7B-%28w%5ETx%2Bb%29%7D%7D&id=fjYzj)
在二分类中![](https://cdn.nlark.com/yuque/__latex/54507b6bac465d8afb0e218ccbf31b59.svg#card=math&code=y_i&id=btAF1)服从**01分布**：
![](https://cdn.nlark.com/yuque/__latex/8b24fa4feb278f4f936a1c10db1cd511.svg#card=math&code=P%28y%3Dy_i%20%7C%20x%29%20%3D%20P%5E%7By_i%7D%281-p%29%5E%7B1-y_i%7D&id=ZLQJQ)
又有：
![](https://cdn.nlark.com/yuque/__latex/a0c89e97cbb10079ebc9580dfb62227f.svg#card=math&code=P%28y%3D1%7Cx%29%2BP%28y%3D0%7Cx%29%20%3D%201&id=eMdSn)
得出：
![](https://cdn.nlark.com/yuque/__latex/91a659b104281f4793f965fa4ae8dfb0.svg#card=math&code=P%28y%3D1%20%7C%20x%29%20%3D%20%5Cfrac%7Be%5E%7Bw%5ETx%2Bb%7D%7D%7B1%2Be%5E%7Bw%5ETx%2Bb%7D%7D&id=DfW9M)
![](https://cdn.nlark.com/yuque/__latex/c02c31c7ea0259b6f608d7bfc52b72b1.svg#card=math&code=P%28y%3D%200%20%7C%20x%29%20%3D%20%5Cfrac%7B1%7D%7B1%2Be%5E%7Bw%5ETx%2Bb%7D%7D&id=qGjZt)
现在要求出已知真实概率![](https://cdn.nlark.com/yuque/__latex/b7e1bbbb0a1e0f5bb9731f08724f76b8.svg#card=math&code=P_s%28y_i%29&id=lEbZj)下的参数![](https://cdn.nlark.com/yuque/__latex/c9b08ae6d9fed72562880f75720531bc.svg#card=math&code=w&id=xMQ7v)和![](https://cdn.nlark.com/yuque/__latex/d29c2e5f4926e5b0e9a95305650f6e54.svg#card=math&code=b&id=XYW42)使得假设![](https://cdn.nlark.com/yuque/__latex/bf98c0ddcbe9c1e535f767c78c3aa813.svg#card=math&code=y&id=qVbaE)近似于![](https://cdn.nlark.com/yuque/__latex/b7e1bbbb0a1e0f5bb9731f08724f76b8.svg#card=math&code=P_s%28y_i%29&id=mR2V2)即![](https://cdn.nlark.com/yuque/__latex/66c53c477d7b57e9c62ed7c9f29dc8d8.svg#card=math&code=p%28y_i%29%20%E2%89%8C%20P_s%28y_i%29&id=GomUI)
属于**模型已定，参数未知**的情况，使用`Maximum-Likelihoo`极大似然法进行求解![](https://cdn.nlark.com/yuque/__latex/c9b08ae6d9fed72562880f75720531bc.svg#card=math&code=w&id=m5QTc)和![](https://cdn.nlark.com/yuque/__latex/d29c2e5f4926e5b0e9a95305650f6e54.svg#card=math&code=b&id=AuDiG)。
给定数据集![](https://cdn.nlark.com/yuque/__latex/74527e6f443a82e596f5e0679afc8bad.svg#card=math&code=%7B%28x_i%2Cy_i%29%5E%7Bm%7D_%7Bi%3D1%7D%7D&id=WOXii)，对率回归模型最大化对数似然得：
![](https://cdn.nlark.com/yuque/__latex/c65d098449b91f386f99d39dec5e84f2.svg#card=math&code=L%28w%2Cb%29%3D%5Cprod_%7Bi%3D1%7D%5E%7Bm%7DP%28y_i%7Cx_i%3Bw%2Cb%29&id=KE1qM)
为防止出现![](https://cdn.nlark.com/yuque/__latex/a38a6ada6eb61ef6996543296be23e47.svg#card=math&code=P%28y_i%29%20%3D%200&id=c777F)的情况和简化计算，对两边进行对数化，不影响似然函数的性质，得**对数似然函数(log-likelihood)**：
![](https://cdn.nlark.com/yuque/__latex/12c66972a27eb01765b4839b04562f08.svg#card=math&code=L_s%28w%2Cb%29%20%3D%20ln%28L%28w%2Cb%29%29%20%3D%20%5Csum%5E%7Bm%7D_%7Bi%3D1%7DlnP%28y_i%20%7C%20x_i%3Bw%2Cb%29&id=tXvz7)
令![](https://cdn.nlark.com/yuque/__latex/c6eb8563bd407da770a2e7bd383aa4a3.svg#card=math&code=%CE%B2%3D%28w%3Bb%29&id=TDNb0)，![](https://cdn.nlark.com/yuque/__latex/b11db94849aa8c99825144dc66014122.svg#card=math&code=%5Chat%7Bx%7D%3D%28x%3B1%29&id=sJn10)，则![](https://cdn.nlark.com/yuque/__latex/3b6a4c273bb97a02c1574a957ca8d615.svg#card=math&code=w%5ETx%2Bb&id=iMDv2)可简写为![](https://cdn.nlark.com/yuque/__latex/e3a3db6288415cf5829f72fe444e1dee.svg#card=math&code=%CE%B2%5ET%5Chat%7Bx%7D&id=SwnoU)，再令![](https://cdn.nlark.com/yuque/__latex/fb981cf60bea3077697f06b2298544b4.svg#card=math&code=P_1%28%5Chat%7Bx%7D%3B%CE%B2%29%3DP%28y%3D1%7C%5Chat%7Bx%7D%3B%CE%B2%29&id=fWYmj)，![](https://cdn.nlark.com/yuque/__latex/bd56faf0c329c4dd4fcb7f9d2d88df07.svg#card=math&code=P_0%28%5Chat%7Bx%7D%3B%CE%B2%29%3DP%28y%3D0%7C%5Chat%7Bx%7D%3B%CE%B2%29%3D1-P_1%28%5Chat%7Bx%7D%3B%CE%B2%29&id=Ux2T2),将上述似然项重写得：
![](https://cdn.nlark.com/yuque/__latex/f8a9156fa40fec43e005cceb82512c8f.svg#card=math&code=P%28y_i%7Cx_i%3Bw%2Cb%29%3Dy_iP_1%28%5Chat%7Bx%7D%3B%CE%B2%29%2B%281-y_i%29P_0%28%5Chat%7Bx%7D%3B%CE%B2%29&id=HBnMz)
代入似然函数中,并使其最大化即最小化：
![](https://cdn.nlark.com/yuque/__latex/7375cbc721418044964c5c34206087dd.svg#card=math&code=L_s%28%CE%B2%29%20%3D%20%5Csum%5E%7Bm%7D_%7Bi%3D1%7D%28%28-y_i%CE%B2%5ET%5Chat%7Bx_i%7D%29%2Bln%281%2Be%5E%7B%28%CE%B2%5ET%5Chat%7Bx_i%7D%29%7D%29&id=WQs35)
最终要求：![](https://cdn.nlark.com/yuque/__latex/34b09b59da51b766633a92fbc325fcdc.svg#card=math&code=%CE%B2%5E%2A%3D%5Cunderset%7B%CE%B2%7D%7BargminL_S%28%CE%B2%29%7D&id=FBdTs)
上式是关于![](https://cdn.nlark.com/yuque/__latex/fe614ad0636b7a9055842f74da955523.svg#card=math&code=%CE%B2&id=cjmEK)的高阶可导连续凸函数，采用凸优化理论中的数值优化算法-**牛顿法（Newton method）**进行迭代优化：
![](https://cdn.nlark.com/yuque/__latex/772c6209a877e48137832578cfdf43a9.svg#card=math&code=x%20%3D%20x_k%20-%20%5Cfrac%7Bf%5Cprime%28x_k%29%7D%7Bf%5Cprime%5Cprime%28x_k%29%7D&id=nqDhN)
将最终的似然函数代入得：
![](https://cdn.nlark.com/yuque/__latex/334cbaea069080f39723bcc7946f96d4.svg#card=math&code=%CE%B2%5Cprime%20%3D%20%CE%B2%20-%20%28%5Cfrac%7B%CF%83%5E2L_s%28%CE%B2%29%7D%7B%CF%83%CE%B2%CF%83%CE%B2%5ET%7D%29%5E%7B-1%7D%5Cfrac%7B%CF%83L_s%28%CE%B2%29%7D%7B%CF%83%CE%B2%7D&id=datWS)
其中关于β的一阶，二阶导数分别为：
![](https://cdn.nlark.com/yuque/__latex/4abf68c3f3e1dc33853a2789644c2398.svg#card=math&code=%5Cfrac%7B%CF%83L_s%28%CE%B2%29%7D%7B%CF%83%CE%B2%7D%20%3D%20-%5Csum%5E%7Bm%7D_%7Bi%3D1%7D%5Chat%7Bx_i%7D%28y_i-P_1%28%5Chat%7Bx_i%7D%3B%CE%B2%29%29&id=ZOwKu)，
![](https://cdn.nlark.com/yuque/__latex/17220967ab9b25d68df070360d6f7a5f.svg#card=math&code=%5Cfrac%7B%CF%83%5E2L_s%28%CE%B2%29%7D%7B%CF%83%CE%B2%CF%83%CE%B2%5ET%7D%3D%5Csum%5E%7Bm%7D_%7Bi%3D1%7D%5Chat%7Bx_i%7D%5Chat%7Bx_i%7D%5E%7BT%7DP_1%28%5Chat%7Bx_i%7D%3B%CE%B2%29%281-P_1%28%5Chat%7Bx_i%3B%CE%B2%7D%29%29&id=eafmz)
代码实现：
使用了牛顿法替代梯度下降进行优化，使用了二维曲面拟合假设曲线，下一次迭代既是使其损失下降最大的位置，也是下降速度最大的位置。
在处理`Sigmod`函数时出现的问题：分母会出现趋于无穷小的情况，导致Sigmod值出现上溢，需要对![](https://cdn.nlark.com/yuque/__latex/e7dc3e3382b0ec5d8365be13e2714aa6.svg#card=math&code=e%5E%7B-z%7D&id=WcBAR)的正负值进行分别处理(未加入)。
```python
class LogisticRegression:

    def __init__(self):
        self.beta = 0

    def fit(self, X, y):
        # n行(样本数量) m列(属性数量)
        (n, m) = X.shape
        y = y.reshape(n, 1)
        # 初始化beta为全1的矩阵
        beta = np.ones((1, m))
        z = X.dot(beta.T)
        # 旧的似然函数
        old_l = 0
        # 新的似然函数
        new_l = np.sum(-y * z + np.log(1 + np.exp(z)))

        while (np.abs(old_l - new_l) > 1e-6):
            p1 = np.exp(z) / (1 + np.exp(z))
            p = np.diag((p1 * (1 - p1)).reshape(n))
            # 一阶导
            first_order = -np.sum(X * (y - p1), 0, keepdims=True)

            # 二阶导
            second_order = X.T.dot(p).dot(X)

            beta -= first_order.dot(np.linalg.inv(second_order))
            z = X.dot(beta.T)

            old_l = new_l
            new_l = np.sum(-y * z + np.log(1 + np.exp(z)))

        self.beta = beta

    def predict(self, X):
        result = self.sigmoid(X.dot(self.beta.T))
        for i, r in enumerate(result):
            if r > 0.5:
                result[i] = 1
            else:
                result[i] = 0

        return result

    @staticmethod
    def sigmoid(x):
        """
        Sigmoid function.
        Input:
            x:np.array
        Return:
            y: the same shape with x
        """
        y = 1.0 / (1 + np.exp(-x))
        return y

```
